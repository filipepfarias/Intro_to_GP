\section{Applications in disease mapping}
\subsection{The model}
% \textcolor{red}{Here we must have defined how the inferencial process occurs.}
There's several applications using GP and here we'll resume an example for disease mapping presented by \cite{Vanhatalo2010Vehtari}. Then let's assume that our phenomenon is ruled by an function $f$. But, we interested in the distribution of them, considering the approach presented in this work. So, we may say that we evaluated each observation $y_i$ from an unknown function $f_i$. With this we assume that our observations and our functions are independent and then we can evaluate our joint distribution for the likehood by the product of each one \cite{jarno2010}.
\begin{subequations}
     \begin{empheq}[left={\empheqlbrace\,}]{align}
      y_1, y_2, \dots, y_n &\sim \prod_{i=1}^{n} Poisson\left( e_i \exp (f_i) \right) \\
      f(\mathbf{x}) | \theta &\sim \mathcal{GP}\left( m(\mathbf{x}),k(\mathbf{x},\mathbf{x}'|\theta) \right) \\
      \theta &\sim \text{half-t}(\nu,A)\text{\footnotemark}
     \end{empheq}
 \end{subequations}\footnotetext{The values $\nu$ and $A$ are not arbitrary, but deterministic \cite{Vanhatalo2010Vehtari}.}

In this case, we used the Poisson distribution for the likelihood because the nature of the process. The phenomenon here is the relative risk of death $\mu$ in a region of the country. So, if we consider $y$ the counting of deaths on this region, we can model the phenomenon with a Poisson process \cite{Vanhatalo2010Vehtari}.

{\color{red}

\subsubsection{Poisson process}


For numerical reasons, we transform $f=\log(\mu)$. Finally, we assume an uncertainty over the parameters of the kernel functions too, then, our hierarchical model stays for the posterior distribution as 
%
\begin{equation}
    p(\mathbf{f}|\mathbf{y},\mathbf{x}) \propto \int p(\mathbf{y}|\mathbf{f})\mathcal{GP}\left(\mathbf{f} | m(\mathbf{x}),k(\mathbf{x},\mathbf{x}'|\theta) \right)p(\theta) d\theta.
\end{equation}

This function isn't analytically tractable because of the Poisson process, but it is possible its evaluation with approximation methods.

}

\begin{figure}  
    \begin{center}
        \begin{tikzpicture}
            % Defining nodes
            \node[obs, fill=red!20!blue!30!white, semithick, draw=red]              (yi) {$y_i$};%
            \node[const, below=.5 of yi, xshift= -.8cm]                        (ei) {$e_i$};
            \node[latent, semithick, draw=red, below=of yi] (fi) {$f_i$};
            
            \node[latent, semithick, draw=red, right=of fi] (f*) {$f_*$};
            \node[latent, semithick, draw=red, left=of fi] (f0) {};
            \node[latent, semithick, draw=red, right=of f*] (f0s) {};

            \node[obs, semithick, above=of f0 ,fill=red!20!blue!30!white, semithick, draw=red]              (y0) {};%
            \node[obs, semithick, above=of f*, fill=red!20!blue!30!white, semithick, draw=red]              (y*) {$y_*$};%
            \node[obs, semithick, above=of f0s ,fill=red!20!blue!30!white, semithick, draw=red]              (y0s) {};%

            \node[latent, semithick, draw=red, below=of fi] (th) {$\theta$};
            \node[const, right= of th, yshift= -.3cm] (A) {$A$};
            \node[const, right= of th, yshift= .3cm] (nu) {$\nu$};


            % Connecting nodes
            \edge[draw=red, semithick] {ei} {yi}; 
            \edge[draw=red, semithick] {fi} {yi};
            \edge[-, draw=red, line width=2pt] {f0} {fi};
            \edge[-, draw=red, line width=2pt] {f*} {fi};
            \edge[draw=red, semithick] {f0} {y0};
            \edge[draw=red, semithick] {f*} {y*};
            \edge[draw=red, semithick] {th} {f0};
            \edge[draw=red, semithick] {th} {f*};
            \edge[draw=red, semithick] {th} {fi};
            \edge[draw=red, semithick] {nu} {th};
            \edge[draw=red, semithick] {A} {th};

            
            % Defining plates
            \plate[draw=blue, very thick] {lkhd} {(ei) (yi) (fi)} {$n$};
        \end{tikzpicture}
    \end{center}
    \caption{Graphical model for the GP for regression. Colored circles represent observed variables and whited ones represent the unknowns. The thick horizontal bar in $f_i$ node represents a set of fully connected nodes of the Gaussian field. Note that an observation $y_i$ is conditionally independent of all other nodes given the corresponding latent variable, $f_i$. Because of the marginalization property of GPs addition of further inputs, $\mathbf{x}$, latent variables, $f$, and unobserved targets, $y_*$, does not change the distribution of any other variables.}
\end{figure}
