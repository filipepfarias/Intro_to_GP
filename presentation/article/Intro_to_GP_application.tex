\section{Applications in disease mapping}
\subsection{The model}
% \textcolor{red}{Here we must have defined how the inferencial process occurs.}
There's several applications using GP and here we'll resume an example for disease mapping presented by \cite{Vanhatalo2010Vehtari}. Then let's assume that our phenomenon is ruled by an function $f$. But, we interested in the distribution of them, considering the approach presented in this work. So, we may say that we evaluated each observation $y_i$ from an unknown function $f_i$. With this we assume that our observations and our functions are independent and then we can evaluate our joint distribution for the likehood by the product of each one \cite{jarno2010}.
\begin{subequations}
     \begin{empheq}[left={\empheqlbrace\,}]{align}
      y_1, y_2, \dots, y_n &\sim \prod_{i=1}^{n} Poisson\left( e_i \exp (f_i) \right) \\
      f(\mathbf{x}) | \theta &\sim \mathcal{GP}\left( m(\mathbf{x}),k(\mathbf{x},\mathbf{x}'|\theta) \right) \\
      \theta &\sim \text{half-t}(\nu,A)\text{\footnotemark}
     \end{empheq}
 \end{subequations}\footnotetext{The values $\nu$ and $A$ are not arbitrary, but deterministic \cite{Vanhatalo2010Vehtari}.}

In this case, we used the Poisson distribution for the likelihood because the nature of the process. The phenomenon here is the relative risk of death $\mu$ in a region of the country. So, if we consider $y$ the counting of deaths on this region, we can model the phenomenon with a Poisson process which mean in each region is given by the increasing rate of deaths. At this point we have defined $e$ as the standardized expected number of deaths \cite{Vanhatalo2010Vehtari}, what multiplied by $\mu$ reveals, in mean, the rate of deaths in that region. For numerical reasons, we transform $f=\log(\mu)$. Finally, we assume an uncertainty over the parameters of the kernel functions too, then, our hierarchical model stays for the posterior distribution as 
%
\begin{equation}
    p(\mathbf{f}|\mathbf{y},\mathbf{x}) \propto \int p(\mathbf{y}|\mathbf{f})\mathcal{GP}\left(\mathbf{f} | m(\mathbf{x}),k(\mathbf{x},\mathbf{x}'|\theta) \right)p(\theta) d\theta.
\end{equation}

This function isn't analytically tractable because of the Poisson process, but it is possible its evaluation with approximation methods.


\begin{figure}  
    \begin{center}
        \begin{tikzpicture}
        
            % Gaussian field
            \node[latent, semithick, draw=red]                 (f1) {$f_i$};%
            \node[const, left=.3 of f1] (fi) {};
            \node[const, right=.3 of f1] (fj) {};
            
            \node[det, draw=red, above=.5 of f1]            (dot) {dot} ;%
        
            % Observations
            \node[obs, above=of dot, semithick, draw=red, fill=red!20!blue!30!white]            (y1)   {$y_i$}; %
            \node[const, below= of f1]          (x1)   {$\mathbf{x}_i$}; %
        
            % Hyperparameters
            \node[latent, semithick, draw=red, below=.5 of f1, xshift=1.5cm] (theta) {$\theta$};%   
            \node[const, right=1.5 of theta, yshift=-0.5cm] (A) {$\nu$} ; %
            \node[const, right=1.5 of theta, yshift=0.5cm]  (nu) {$A$} ; %
            \factor[right=of theta, fill=red] {theta-factor} {above:$\text{half-t}$} {A,nu} {theta};
            
            % Expected number of deaths
            \node[const, left=.5 of dot] (e1) {$e_i$} ; %
        
            % Poisson process
            \factor[above=of dot, fill=red] {dot-y1} {left:$\text{Poisson}$} {dot} {y1} ; %
        
            % Connect e1 to the dot node
            \edge[-, draw=red] {e1,f1} {dot} ;
            \edge[draw=red] {x1} {f1};
            \edge[draw=red] {theta} {f1};
            \edge[-,line width=2pt, draw=red] {fi} {f1};
            \edge[-,line width=2pt, draw=red] {fj} {f1};
            \edge[-,draw=red]{A} {theta-factor};
            \edge[-,draw=red]{nu} {theta-factor};
            \edge[->,draw=red] {theta-factor} {theta};
            \edge[-,draw=red]{nu} {theta-factor};
            \edge[->,draw=red]{dot} {y1};
        
            % Plates
            \plate[draw=blue, very thick] {gpobs} {(y1) (dot) (e1) (fi) (fj) (x1) (f1) (dot-y1)} {$N$};
            \plate[draw=blue, very thick] {gpf} {(f1) (fi) (fj)} {$\mathcal{H}$};
          
          \end{tikzpicture}
    \end{center}
    \caption{Graphical model for the GP for regression. Colored circles represent observed variables and whited ones represent the unknowns. The thick horizontal bar represents a set of fully connected nodes of the Gaussian field. Note that an observation $y_i$ is conditionally independent of all other nodes given the corresponding latent variable, $f_i$. Because of the marginalization property of GPs addition of further inputs, $\mathbf{x}$, latent variables, $f$, and unobserved targets, $y_*$, does not change the distribution of any other variables.}
\end{figure}